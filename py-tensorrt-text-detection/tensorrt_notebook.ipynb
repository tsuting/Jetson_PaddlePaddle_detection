{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13ae1dd",
   "metadata": {},
   "source": [
    "# ONNX to TensorRT and inference with TensorRT\n",
    "\n",
    "This notebook demonstrates how to convert onnx model to TensorRT engine and then inference\n",
    "with TensorRT engine.\n",
    "\n",
    "We use [PaddlePaddle](https://github.com/PaddlePaddle/PaddleOCR) text detection model for demonstration\n",
    "purpose. If you have any questions regarding the *model* itself, please create an issue in the original\n",
    "paddlepaddle repo.\n",
    "\n",
    "Please make sure you have run `pip install -r requirements.txt` both in this folder and the parent folder\n",
    "to make sure all necessary packages are installed.\n",
    "\n",
    "For installation and environment setup, please refer to [README](README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f3b77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb5b1d",
   "metadata": {
    "lines_to_next_cell": 0,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from trt_utils import TRTUtils\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from model_common import build_pre_process, build_post_process\n",
    "from model_common.utils import viz_pddle_distill_db_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e4e01",
   "metadata": {},
   "source": [
    "## Inference using the TensoRT Engine\n",
    "\n",
    "This part is the same as the normal onnx inference process, but with tensorRT inference\n",
    "instead of onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ff342",
   "metadata": {
    "lines_to_next_cell": 2,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "213b7f5b",
   "metadata": {},
   "source": [
    "### Text Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42462df",
   "metadata": {},
   "source": [
    "Perform preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c497752",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_img_path = \"../sample_images/nutrition_label.jpg\"\n",
    "test_img = cv2.imread(test_img_path)\n",
    "pre_process_op = build_pre_process({\"name\": \"td_PaddlePaddlePreProcess\"})\n",
    "test_in, to_postprocess = pre_process_op(raw_img=test_img, dimension=(960,960))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf79107",
   "metadata": {},
   "source": [
    "Run inference with tensorRT\n",
    "\n",
    "Important to use pycuda here. The autoinit will automatically initialize GPU device.\n",
    "If not autoinit, an error will occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8610c93",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_trt_config = {\n",
    "            \"fp16\":True,\n",
    "            \"original_model_path\":  \"../models/ch_PP-OCRv2_det_infer.onnx\",\n",
    "            \"engine_path\":\"../models/ch_PP-OCRv2_det_infer.engine\",\n",
    "            \"dynamic_shape\": True,\n",
    "            \"profile_config\":[\n",
    "                {\"x\" : [(1, 3, 960, 960), (1, 3, 1280, 1280), (1, 3, 1536,1536) ] }\n",
    "            ]\n",
    "        }\n",
    "static_trt_config = {\n",
    "    \"fp16\":True,\n",
    "    \"original_model_path\": \"../models/ch_PP-OCRv2_det_infer.onnx\",\n",
    "    \"engine_path\":\"../models/ch_PP-OCRv2_det_infer_static.engine\",\n",
    "    \"dynamic_shape\": False,\n",
    "    \"profile_config\":[\n",
    "        {\"x\" : [(1, 3, 1088, 1440)] }\n",
    "    ]\n",
    "}\n",
    "trt_utils = TRTUtils(dynamic_trt_config)\n",
    "trt_utils.get_engine()\n",
    "output_buffer = trt_utils.inference_single(test_in, profiling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c635c5e",
   "metadata": {
    "lines_to_next_cell": 0,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# reshape\n",
    "output_shape = list(test_in.shape)\n",
    "output_shape[1] = 1\n",
    "output_shape = [1] + output_shape\n",
    "results = np.reshape(output_buffer[0],output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e04663",
   "metadata": {},
   "source": [
    "Perform post-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba24de",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "postprocess_params = {\n",
    "    \"name\": \"td_PaddlePaddlePostProcess\",\n",
    "    \"thresh\": 0.3,\n",
    "    \"box_thresh\": 0.5,\n",
    "    \"max_candidate\": 1000,\n",
    "    \"unclip_ratio\": 2,\n",
    "    \"use_dilation\": False,\n",
    "    \"score_mode\": \"fast\",\n",
    "}\n",
    "post_process_op = build_post_process(postprocess_params)\n",
    "dt_boxes = post_process_op(results=results, **to_postprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8649b",
   "metadata": {},
   "source": [
    "Viz the prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633475d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "viz_img = viz_pddle_distill_db_results(test_img.copy(), dt_boxes=dt_boxes)\n",
    "plt.imshow(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6df70",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb991b39",
   "metadata": {},
   "source": [
    "### Text Recognition"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorrt]",
   "language": "python",
   "name": "conda-env-tensorrt-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
